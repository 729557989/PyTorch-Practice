{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM的使用示例 (GRU的参数同GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64     # 句子的数量\n",
    "seq_len = 20        # 句子的长度\n",
    "vocab_size = 100    # 词典的数量\n",
    "embedding_dim = 30  # 用长度为30的向量来表示一个词语\n",
    "hidden_size = 18    # 隐层中LSTM的个数\n",
    "num_layers = 2      # 多少个隐藏层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个batch的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(low=0, high=100,size=[batch_size, seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据经过embedding处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedded = embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(100, 30)\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20, 30])\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n",
    "print(input.shape)\n",
    "print(input_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把embedding之后的数据传给LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=embedding_dim,\n",
    "               hidden_size=hidden_size,\n",
    "               num_layers=num_layers,\n",
    "               batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (h_n, c_n) = lstm(input_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if Bidrectional = False -> 1, if Bidirectional = False -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM layer spec:  LSTM(30, 18, num_layers=2, batch_first=True)\n",
      "shape for input_embedded:  torch.Size([64, 20, 30])\n",
      "shape for output:  torch.Size([64, 20, 18])\n",
      "shape for h_n:  torch.Size([2, 64, 18])\n",
      "shape for c_n:  torch.Size([2, 64, 18])\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM layer spec: \", lstm)\n",
    "print(\"shape for input_embedded: \", input_embedded.shape)\n",
    "print(\"shape for output: \", output.shape) # [62, 20, 18 * bidirectional = False], 而20表示了time step\n",
    "print(\"shape for h_n: \", h_n.shape)       # [num_layers * bidirectional = False, 64, 18]\n",
    "print(\"shape for c_n: \", c_n.shape)       # [num_layers * bidirectional = False, 64, 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取最后一个时间步(time step)上的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1624, -0.1872,  0.0287,  ..., -0.0135,  0.0211,  0.0261],\n",
       "        [ 0.1659, -0.1820, -0.0288,  ..., -0.0564,  0.0506,  0.0176],\n",
       "        [ 0.2006, -0.1585,  0.0334,  ...,  0.0230,  0.0515, -0.0073],\n",
       "        ...,\n",
       "        [ 0.1631, -0.2159,  0.0200,  ..., -0.0376,  0.0608,  0.0452],\n",
       "        [ 0.2187, -0.1842,  0.0560,  ...,  0.0190,  0.0658,  0.0201],\n",
       "        [ 0.1926, -0.1968,  0.0103,  ..., -0.0367,  0.0525, -0.0333]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_output = output[:, -1, :]\n",
    "last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取最后一次的hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1624, -0.1872,  0.0287,  ..., -0.0135,  0.0211,  0.0261],\n",
       "        [ 0.1659, -0.1820, -0.0288,  ..., -0.0564,  0.0506,  0.0176],\n",
       "        [ 0.2006, -0.1585,  0.0334,  ...,  0.0230,  0.0515, -0.0073],\n",
       "        ...,\n",
       "        [ 0.1631, -0.2159,  0.0200,  ..., -0.0376,  0.0608,  0.0452],\n",
       "        [ 0.2187, -0.1842,  0.0560,  ...,  0.0190,  0.0658,  0.0201],\n",
       "        [ 0.1926, -0.1968,  0.0103,  ..., -0.0367,  0.0525, -0.0333]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state = h_n[-1, :, :]\n",
    "#1  #第一层的正向\n",
    "#-1 #第一层的反向\n",
    "#1  #第二层的正向\n",
    "#-1 #第二层的反向\n",
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output, 把每个时间步上的结果再seq_len这一维度进行了拼接\n",
    "# h_n, 把不同层的隐藏状态在第0个维度上进行了拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_state == last_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[0, 1, 2], [3, 4, 5]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[6, 7, 8], [9, 10, 11]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  6,  7,  8],\n",
       "        [ 3,  4,  5,  9, 10, 11]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([x, y], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b44562fb7f1a4e836c26bd2df6d17a92863a39e22a29c04c28fe2e17e7662947"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
